{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パーセプトロンからニューラルネットワークへ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤔ニューラルネットワークってどういう発想からきてるのさ\n",
    "\n",
    "> ニューラルネットワーク（神経網、英: neural network、略称: NN）は、脳機能に見られるいくつかの特性に類似した数理的モデルである。\n",
    "> [ニューラルネットワーク - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)\n",
    "\n",
    "ｽｳﾘﾃｷﾓﾃﾞﾙと言われましても…というわけで、過去自分が聞いた程度の話でまとめると\n",
    "\n",
    "* 動物の脳は多数の神経細胞でできている\n",
    "* 神経細胞は **シナプス** で繋がっている\n",
    "* シナプスには入力と出力がある\n",
    "\n",
    "と、脳の神経細胞をモデルとしたもので、これがあれば人の脳に近いものができるんじゃね？という発想からきている、らしい。  \n",
    "\n",
    "※ネタバレ: 実際は作るのに膨大なデータと時間が必要なので、ほんの一部のことしかできない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークの例\n",
    "\n",
    "![Neural Network](../draw.io/neural-network.svg)\n",
    "\n",
    "* 左から **入力層**, **中間層**, **出力層** と呼ばれる\n",
    "* 本では順に *第0層*, *第1層*, *第2層* と呼ぶことにしている\n",
    "* この本では、図のように重みを持つ層が2つあることからを **2層ネットワーク** としているが、書籍によってはネットワークを構成する層から *3層ネットワーク*とする場合もある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パーセプトロンを、ニューラルネットワークの形に変形させてみよう\n",
    "\n",
    "パーセプトロンはこういう図で表すことができる:  \n",
    "![Perceptron](../draw.io/perceptron.svg)\n",
    "\n",
    "式はこうだ。  \n",
    "2つの入力$x_1$,$x_2$と、それぞれの重み$w_1$,$w_2$と、閾値$\\theta$を比較した条件式の出力$y$は:\n",
    "$$\n",
    "     y = \n",
    "         \\begin{cases}\n",
    "             0 \\quad (w_1 x_1 + w_2 x_2 \\leqq \\theta) \\\\\n",
    "             1 \\quad (w_1 x_1 + w_2 x_2 > \\theta) \\\\\n",
    "         \\end{cases}\n",
    "$$\n",
    "\n",
    "そして、$\\theta$をバイアス($- b$)に置き換えて、式変形をするとこうなった:\n",
    "$$\n",
    "     y = \n",
    "         \\begin{cases}\n",
    "             0 \\quad (b + w_1 x_1 + w_2 x_2 \\leqq 0) \\\\\n",
    "             1 \\quad (b + w_1 x_1 + w_2 x_2 > 0) \\\\\n",
    "         \\end{cases}\n",
    "$$\n",
    "\n",
    "では、これを先ほどの図に表すと…？:  \n",
    "![Perceptron](../draw.io/perceptron-add-bias.svg)\n",
    "\n",
    "何が言いたいかというと、バイアス($b$)は別の入力の重み、と言い換えられるということである。\n",
    "\n",
    "ところが、この図には問題がある。出力$y$の中身は計算した結果にしなければならないが、図の$y$は関数ではなく、変数だ。$y$には隠された関数がいるはずだ。  \n",
    "(と、解釈することで「なんで突然、入力の総和$a$なんて言い出したんだ」という疑問の解決になるはず…)\n",
    "\n",
    "隠された関数を定義しなければならないので、数式を変形させよう。\n",
    "\n",
    "まず注目すべき場所は、条件式の中にある$b + w_1 x_1 + w_2 x_2$だ。この結果を条件式で使うなら、変数に入れた方がまとめられそうだ。この結果を$a$としよう。\n",
    "\n",
    "$$\n",
    "    a = b + w_1 x_1 + w_2 x_2\n",
    "$$\n",
    "\n",
    "条件式を置き換えてみよう:\n",
    "$$\n",
    "    y = \n",
    "         \\begin{cases}\n",
    "             0 \\quad (a \\leqq 0) \\\\\n",
    "             1 \\quad (a > 0) \\\\\n",
    "         \\end{cases}\n",
    "$$\n",
    "\n",
    "すっきりしてきた。一旦図にしてみよう:  \n",
    "![Perceptron](../draw.io/perceptron-replace-y.svg)\n",
    "\n",
    "おっと、図にすると条件式を書かざるを得ない。見にくいので、この条件式を$h()$関数としよう。数式ではこうだ:\n",
    "$$\n",
    "    h(a) =\n",
    "        \\begin{cases}\n",
    "             0 \\quad (a \\leqq 0) \\\\\n",
    "             1 \\quad (a > 0) \\\\\n",
    "         \\end{cases}\n",
    "$$\n",
    "$$\n",
    "    y = h(a)\n",
    "$$\n",
    "\n",
    "では、図にしてみよう:  \n",
    "![Perceptron](../draw.io/perceptron-replace-h.svg)\n",
    "\n",
    "\n",
    "よさそうだ。これ以上まとめるものがない。  \n",
    "では、必要な数式をいったんまとめよう。\n",
    "\n",
    "2つの入力$x_1$,$x_2$と、それぞれの重み$w_1$,$w_2$の結果$a$は:\n",
    "$$\n",
    "    a = b + w_1 x_1 + w_2 x_2 \\\\\n",
    "$$\n",
    "\n",
    "そして、$a$を利用した関数$h()$の式は:\n",
    "$$\n",
    "    h(a) =\n",
    "        \\begin{cases}\n",
    "             0 \\quad (a \\leqq 0) \\\\\n",
    "             1 \\quad (a > 0) \\\\\n",
    "         \\end{cases}\n",
    "$$\n",
    "\n",
    "関数$h()$の結果$y$は:\n",
    "$$\n",
    "    y = h(a)\n",
    "$$\n",
    "\n",
    "おお、前に「$x_1$,$x_2$と、それぞれの重み$w_1$,$w_2$と、閾値$\\theta$を比較した条件式の出力$y$」とか長ったらしくて一瞬「？」になったものが、わかりやすく説明できるようになった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数\n",
    "\n",
    "関数$h()$のように、入力信号の総和を出力信号に変換っする関数は、一般的に **活性化関数** (activation function)と呼ばれる。\n",
    "\n",
    "また、今まで図で表していた〇を「ノード」または「ニューロン」と呼ぶ。\n",
    "\n",
    "活性化関数のアルゴリズムは、パーセプトロンのほかにもある。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
